# A Generative AI based Chatbot


## ðŸš€ Project Workflow


# **Step 1 â€“ Setup Memory for LLM (Vector Database)**

**1. Load raw PDFs** â€” import medical or knowledge base documents.

**2. Create text chunks** â€” split large documents into manageable segments.

**3. Generate vector embeddings** â€” convert chunks into numerical representations using HuggingFace embeddings.

**4. Store embeddings in FAISS** â€” build a searchable vector database to enable fast and accurate retrieval.


# **Step 2 â€“ Connect Memory with LLM**
**1. Setup LLM (Mistral via HuggingFace)** â€” load the generative language model for response generation.

**2. Integrate LLM with FAISS** â€” allow the model to retrieve relevant context before answering.

**3. Create a RAG chain** â€” combine retrieval and generation to produce informed, context-aware responses.


# **Step 3 â€“ Build the Chatbot UI**

**1. Develop chatbot interface with Streamlit** â€” create a user-friendly, interactive front end.

**2. Load the FAISS vector store into cache** â€” ensure quick access to the knowledge base.

**3. Enable RAG-based responses** â€” generate real-time, accurate medical insights powered by generative AI.
